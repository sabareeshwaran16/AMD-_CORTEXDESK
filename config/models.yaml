# AI Models Configuration
# All models run locally - no cloud calls

# Local LLM (via Ollama)
llm:
  provider: ollama
  base_url: http://localhost:11434
  model: llama3:8b
  temperature: 0.7
  max_tokens: 2048

# Embeddings Model
embeddings:
  provider: sentence-transformers
  model: all-MiniLM-L6-v2
  device: cpu  # or cuda if GPU available

# Speech-to-Text (Offline)
stt:
  provider: faster-whisper
  model: base
  device: cpu  # or cuda if GPU available
  language: null  # auto-detect

# NLP Models
nlp:
  spacy_model: en_core_web_sm  # or en_core_web_trf for better accuracy
  language_detection: langdetect

# Vector Database
vector_db:
  provider: chroma
  persist_directory: data/embeddings
  collection_name: cortexdesk_documents

